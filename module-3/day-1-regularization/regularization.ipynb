{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ridge & Lasso & Regularization\n",
    "\n",
    "## Objectives \n",
    "<a name=\"objectives\"></a>\n",
    "\n",
    "- List methods other than r-squared to assess model fit\n",
    "\n",
    "- Describe regularization's role in regression\n",
    "\n",
    "- Summarize the difference between L1 and L2 norms\n",
    "\n",
    "- Understand the effect of hyper-parameter $\\alpha$ in Ridge and Lasso.\n",
    "\n",
    "- Compare and contrast between Lasso-Ridge-Linear models.\n",
    "\n",
    "- Apply Lasso and Ridge with sklearn and understand the parameters.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 0: Review \n",
    "## Review Linear Regression once again:\n",
    "![imune](https://media3.giphy.com/media/l4FGBBs6fjtZXzXCE/giphy.gif?cid=ecf05e47dbb74b8bcd3cf3aafbc86e24452503799b466084&rid=giphy.gif)\n",
    "\n",
    "\n",
    "__Linear Model__\n",
    "\n",
    "\n",
    "$$ Y = w_{0} + w_{1}X_1 + w_{2}X_{2} + \\cdots + w_{p}X_{p} + \\varepsilon $$\n",
    "\n",
    " - We train model to understand the paramaters $w_{i}$ \n",
    " \n",
    " - Use linear algebra or gradient descent to find parameters to minimize:\n",
    " \n",
    " Note that the predictions are given by:\n",
    " \n",
    " $$ \\hat{y}_{i} =  w_{0} + w_{1}X_{i1} + w_{2}X_{i2} + \\cdots + w_{p}X_{i_p}$$\n",
    " \n",
    " Therefore individual errors are given by:\n",
    " \n",
    " $$ e_{i} = y_{i} - \\hat{y}_{i} $$\n",
    " \n",
    " As a result, the residual sum of squares can be expressed as:\n",
    " \n",
    " $$ RSS(\\boldsymbol{w}) = \\sum\\limits_{i=0}^{N} e_{i}^{2}$$\n",
    " \n",
    " \n",
    " \n",
    " $$ J(\\boldsymbol{w}) = \\sum\\limits_{i=0}^{N} (y_{i} - w_{0} - w_{1}X_{i1} - w_{2}X_{i2} - \\cdots - w_{p}X_{i_p})^{2} $$\n",
    " \n",
    " And this equation can be written in short hand as:\n",
    " \n",
    " $$ J(\\boldsymbol{w}) = \\rvert \\boldsymbol{y} - X \\boldsymbol{w} \\rvert^{2} $$\n",
    " \n",
    " or with betas as we are used to seeing them:\n",
    " \n",
    " $$ \\text{cost_function}= \\sum_{i=1}^n(y_i - \\hat{y})^2 = \\sum_{i=1}^n(y_i - \\sum_{j=1}^k(b_jx_{ij} + b))^2$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question: What methods or metrics have you learned to assess model fit?\n",
    "\n",
    "\n",
    "## Another Question: How do those metrics feel about adding more variables to the model?\n",
    "\n",
    "![schitts](https://media1.giphy.com/media/fXtGlVSI2ZB2E1JO0b/giphy.gif?cid=ecf05e47f55093929090866ffd59873c647521e25e164830&rid=giphy.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Review\n",
    "<a name=\"review\"></a>\n",
    "\n",
    "\n",
    "\n",
    "[__Overfitting - Underfitting__](https://github.com/gokererdogan/JaverianaMLCourse/blob/master/Lectures/05.pdf)\n",
    "\n",
    "<img src=\"underfitting_overfitting.png\" alt=\"Bias-Variance\" style=\"width: 500px;\"/>\n",
    "\n",
    "[__Bias - Variance Trade-Off__](http://scott.fortmann-roe.com/docs/BiasVariance.html)\n",
    "\n",
    "<img src=\"bias_variance_trade_off.png\" alt=\"Bias-Variance\" style=\"width: 400px;\"/>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## New Tools:\n",
    "- AIC & BIC to compare models\n",
    "- Regularization to produce a better model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1: AIC & BIC\n",
    "## Calculating AIC and BIC \n",
    "AIC and BIC are information criteria for evaluating model performance. These measures compute the goodness of fit with the estimated parameters, but apply a penalty function on the number of parameters in the model.\n",
    "\n",
    "\n",
    "The BIC is also known as the _Schwarz information criterion (abrv. SIC)_ or the Schwarz-Bayesian information criteria. The AIC is also known as the Akaike information criterion. Both criterion were developed in the 1970s.\n",
    "\n",
    "- AIC is defined as: $2k - 2log(L)$\n",
    "- BIC is defined as: $klog(n) - 2log(L)$  \n",
    "\n",
    "$n$ = sample size <br>\n",
    "$k$ = variables in model <br>\n",
    "$L$ = log of sse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def aic(y, y_pred, k):\n",
    "    resid = y - y_pred\n",
    "    sse = (resid**2).sum()\n",
    "    AIC = 2*k - 2*np.log(sse)\n",
    "    \n",
    "    return AIC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bic(y, y_pred, k, n):\n",
    "    resid = y - y_pred\n",
    "    sse = (resid**2).sum()\n",
    "    BIC = np.log(n) + n*np.log(sse/n)\n",
    "    \n",
    "    return BIC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AIC & BIC in comparsion\n",
    "\n",
    "Both AIC and BIC are only useful in comparing the performance of two different model specifications and **cannot** be used on their own. \n",
    "\n",
    "_**Lower**_ AIC and BIC are better. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Regularization\n",
    "\n",
    "## Regularization Techniques\n",
    "\n",
    "\n",
    "- Why?\n",
    "\n",
    "    - Reduces complexity\n",
    "    \n",
    "    - Reduce the chance of overfitting.\n",
    "    \n",
    "    - Reduces model's variance at the expense of introducing small bias\n",
    "    \n",
    "    - Increases model's interprettability.\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2a: Ridge regularization (L2 Norm)\n",
    "![ridge](https://media2.giphy.com/media/3Aie9MmJ0klyM/giphy.gif?cid=ecf05e472724cf8b955fe4da2a1050dd8865bec22b629736&rid=giphy.gif)\n",
    "\n",
    "Instead of minimizing $J(w)$ (least squares method), we will minimize:\n",
    "\n",
    "$$ J_{\\alpha}(\\boldsymbol{w}) = J(\\boldsymbol{w}) + \\alpha\\sum_{i=1}^{p} w_{i}^{2} $$\n",
    "\n",
    "Function is in sklearn as [Ridge](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Ridge.html)\n",
    "\n",
    "The **goal** of ridge regression is to find  the right alpha that best manages multicolinearity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ridge regression applies a penalizing parameter $\\lambda$ *slope* $^2$, such that a small bias will be introduced to the entire model depending on the value of $\\lambda$, which is called a *hyperparameter*. \n",
    "\n",
    "$$ \\text{cost_function_ridge}= \\sum_{i=1}^n(y_i - \\hat{y})^2 = \\sum_{i=1}^n(y_i - \\sum_{j=1}^k(b_jx_{ij} + b))^2 + \\lambda \\sum_{j=1}^p b_j^2$$\n",
    "\n",
    "The result of applying such a penalizing parameter to the cost function, resulting a different regression model that minimizing the residual sum of square **and** the term $\\lambda \\sum_{j=1}^p b_j^2$. \n",
    "\n",
    "The Ridge regression improves the fit of the original regression line by introducing some bias/changing the slope and intercept of the original line. Recall the way we interpret a regression model Y = mx + b: with every unit increase in x, the outcome y increase by m unit. Therefore, the bigger the coefficient m is, the more the outcome is subjected to changes in predictor x. Ridge regression works by reducing the magnitude of the coefficient m and therefore reducing the effect the predictors have on the outcome. Let's look at a simple example.\n",
    "\n",
    "The ridge regression penalty term contains all of the coefficients squared from the original regression line except for the intercept term. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2a: Lasso regularization (L1 Norm)\n",
    "![lasso](https://media3.giphy.com/media/wRKeX8o1eIxxu/giphy.gif?cid=ecf05e47a70490d9dee94f19dd8876390c0ef88243356922&rid=giphy.gif)\n",
    "\n",
    "Instead of minimizing $J(\\boldsymbol{\\omega})$, we will minimize:\n",
    "\n",
    "$$ J_{\\alpha}(\\boldsymbol{w}) = J(\\boldsymbol{w}) + \\alpha\\sum_{i=1}^{p}| w_{i} | $$\n",
    "\n",
    "Function in skelarn as [Lasso](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Lasso.html)\n",
    "\n",
    "The **goal** of lasso regression is to obtain the subset of predictors and increase model interpretability."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lasso regression is very similar to Ridge regression except for one difference - the penalty term is not squared but the absolute values of the coefficients muliplied by lambda, expressed by:\n",
    "\n",
    "$$ \\text{cost_function_lasso}= \\sum_{i=1}^n(y_i - \\hat{y})^2 = \\sum_{i=1}^n(y_i - \\sum_{j=1}^k(b_jx_{ij} + b))^2 + \\lambda \\sum_{j=1}^p \\mid b_j \\mid$$\n",
    "\n",
    "The biggest difference in Ridge and Lasso is that Lasso simultaneously performs variable selection: some coefficients are shrunk to 0, rendering them nonexistence in the original regression model. Therefore, Lasso regression performs very well when you have higher dimensional dataset where some predictors are useless; whereas Ridge works best when all the predictors are needed. \n",
    "\n",
    "<img src=\"https://media.giphy.com/media/AWeYSE0qgpk76/giphy.gif\" width= \"400\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# implementation \n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.linear_model import Lasso, Ridge, LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "data = sns.load_dataset('mpg')\n",
    "\n",
    "#data = pd.read_csv(\"https://raw.githubusercontent.com/learn-co-curriculum/dsc-2-24-09-ridge-and-lasso-regression/master/auto-mpg.csv\") \n",
    "data = data.sample(50)\n",
    "y = data[[\"mpg\"]]\n",
    "X = data.drop([\"mpg\", \"name\", \"origin\"], axis=1)\n",
    "\n",
    "scale = MinMaxScaler()\n",
    "transformed = scale.fit_transform(X)\n",
    "X = pd.DataFrame(transformed, columns = X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50, 9)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mpg</th>\n",
       "      <th>cylinders</th>\n",
       "      <th>displacement</th>\n",
       "      <th>horsepower</th>\n",
       "      <th>weight</th>\n",
       "      <th>acceleration</th>\n",
       "      <th>model_year</th>\n",
       "      <th>origin</th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>392</th>\n",
       "      <td>27.0</td>\n",
       "      <td>4</td>\n",
       "      <td>151.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>2950</td>\n",
       "      <td>17.3</td>\n",
       "      <td>82</td>\n",
       "      <td>usa</td>\n",
       "      <td>chevrolet camaro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>24.0</td>\n",
       "      <td>4</td>\n",
       "      <td>113.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>2372</td>\n",
       "      <td>15.0</td>\n",
       "      <td>70</td>\n",
       "      <td>japan</td>\n",
       "      <td>toyota corona mark ii</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>20.0</td>\n",
       "      <td>4</td>\n",
       "      <td>140.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>2408</td>\n",
       "      <td>19.5</td>\n",
       "      <td>72</td>\n",
       "      <td>usa</td>\n",
       "      <td>chevrolet vega</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>19.0</td>\n",
       "      <td>6</td>\n",
       "      <td>250.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>3282</td>\n",
       "      <td>15.0</td>\n",
       "      <td>71</td>\n",
       "      <td>usa</td>\n",
       "      <td>pontiac firebird</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>14.0</td>\n",
       "      <td>8</td>\n",
       "      <td>351.0</td>\n",
       "      <td>153.0</td>\n",
       "      <td>4129</td>\n",
       "      <td>13.0</td>\n",
       "      <td>72</td>\n",
       "      <td>usa</td>\n",
       "      <td>ford galaxie 500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      mpg  cylinders  displacement  horsepower  weight  acceleration  \\\n",
       "392  27.0          4         151.0        90.0    2950          17.3   \n",
       "14   24.0          4         113.0        95.0    2372          15.0   \n",
       "60   20.0          4         140.0        90.0    2408          19.5   \n",
       "47   19.0          6         250.0       100.0    3282          15.0   \n",
       "65   14.0          8         351.0       153.0    4129          13.0   \n",
       "\n",
       "     model_year origin                   name  \n",
       "392          82    usa       chevrolet camaro  \n",
       "14           70  japan  toyota corona mark ii  \n",
       "60           72    usa         chevrolet vega  \n",
       "47           71    usa       pontiac firebird  \n",
       "65           72    usa       ford galaxie 500  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=False)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Perform t`est train split\n",
    "X_train , X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=12)\n",
    "\n",
    "# Build a Ridge, Lasso and regular linear regression model. \n",
    "# Note how in scikit learn, the regularization parameter is denoted by alpha (and not lambda)\n",
    "ridge = Ridge(alpha=0.5)\n",
    "ridge.fit(X_train, y_train)\n",
    "\n",
    "lasso = Lasso(alpha=0.5)\n",
    "lasso.fit(X_train, y_train)\n",
    "\n",
    "lin = LinearRegression()\n",
    "lin.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unpenalized Linear Regression Coefficients are:[[ -5.29758604   3.76277395  -4.73080379 -12.86667797  -1.22350324\n",
      "    6.23098928]]\n",
      "Unpenalized Linear Regression Intercept:[28.65251888]\n"
     ]
    }
   ],
   "source": [
    "print(\"Unpenalized Linear Regression Coefficients are:{}\".format(lin.coef_))\n",
    "print(\"Unpenalized Linear Regression Intercept:{}\".format(lin.intercept_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lasso Regression Coefficients are:[-11.0464033   -0.          -0.          -0.71872524   0.\n",
      "   0.        ]\n",
      "Lasso Linear Regression Intercept:[27.56032067]\n"
     ]
    }
   ],
   "source": [
    "print(\"Lasso Regression Coefficients are:{}\".format(lasso.coef_))\n",
    "print(\"Lasso Linear Regression Intercept:{}\".format(lasso.intercept_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ridge Regression Coefficients are:[[-4.52496612 -2.49905166 -4.82731659 -6.48664034 -0.87419988  4.838374  ]]\n",
      "Ridge Linear Regression Intercept:[28.21881157]\n"
     ]
    }
   ],
   "source": [
    "print(\"Ridge Regression Coefficients are:{}\".format(ridge.coef_))\n",
    "print(\"Ridge Linear Regression Intercept:{}\".format(ridge.intercept_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create predictions\n",
    "y_h_ridge_train = ridge.predict(X_train)\n",
    "y_h_ridge_test = ridge.predict(X_test)\n",
    "\n",
    "y_h_lasso_train = np.reshape(lasso.predict(X_train),(40,1))\n",
    "y_h_lasso_test = np.reshape(lasso.predict(X_test),(10,1))\n",
    "\n",
    "y_h_lin_train = lin.predict(X_train)\n",
    "y_h_lin_test = lin.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40, 1)\n",
      "(10, 1)\n"
     ]
    }
   ],
   "source": [
    "print(y_h_ridge_train.shape)\n",
    "print(y_h_ridge_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "print(type(y_h_lasso_train))\n",
    "print(type(y_h_ridge_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Examining the Residual for Ridge, Lasso, and Unpenalized Regression coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Error Ridge Model mpg    207.134401\n",
      "dtype: float64\n",
      "Test Error Ridge Model mpg    92.642092\n",
      "dtype: float64\n",
      "\n",
      "\n",
      "Train Error Lasso Model mpg    442.513584\n",
      "dtype: float64\n",
      "Test Error Lasso Model mpg    281.358958\n",
      "dtype: float64\n",
      "\n",
      "\n",
      "Train Error Unpenalized Linear Model mpg    189.229442\n",
      "dtype: float64\n",
      "Test Error Unpenalized Linear Model mpg    65.877605\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# examine the residual sum of sq\n",
    "print('Train Error Ridge Model', np.sum((y_train - y_h_ridge_train)**2))\n",
    "print('Test Error Ridge Model', np.sum((y_test - y_h_ridge_test)**2))\n",
    "print('\\n')\n",
    "\n",
    "print('Train Error Lasso Model', np.sum((y_train - y_h_lasso_train)**2))\n",
    "print('Test Error Lasso Model', np.sum((y_test - y_h_lasso_test)**2))\n",
    "print('\\n')\n",
    "\n",
    "print('Train Error Unpenalized Linear Model', np.sum((y_train - lin.predict(X_train))**2))\n",
    "print('Test Error Unpenalized Linear Model', np.sum((y_test - lin.predict(X_test))**2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Part 2c: Crossvalidation to Optimize the Regularization Hyperparameter\n",
    "\n",
    "The regularization strength could sensibly be any nonnegative number, so there's no way to check \"all possible\" values. It's often useful to try several values that are different orders of magnitude."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "alphas = [1, 10, 100, 1000, 10000]\n",
    "train_scores = []\n",
    "test_scores = []\n",
    "\n",
    "for alpha in alphas:\n",
    "    rr = Ridge(alpha=alpha, random_state=42)\n",
    "    # upate the names of your datasets\n",
    "    rr.fit(X_train, y_train)\n",
    "    train_score = rr.score(X_train, y_train)\n",
    "    test_score = cross_val_score(rr, X_test, y_test).mean()\n",
    "    \n",
    "    train_scores.append(train_score)\n",
    "    test_scores.append(test_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.style.use('fivethirtyeight')\n",
    "fig, ax = plt.subplots()\n",
    "plt.xscale('log')\n",
    "plt.title('Ridge $R^2$ as a function of regularization strength')\n",
    "ax.set_xlabel('Regularization strength $\\lambda$')\n",
    "ax.set_ylabel('$R^2$')\n",
    "ax.plot(alphas, train_scores, label='train')\n",
    "ax.plot(alphas, test_scores, label='test')\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Practice\n",
    "\n",
    "__Your Turn__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>culmen_length_mm</th>\n",
       "      <th>culmen_depth_mm</th>\n",
       "      <th>flipper_length_mm</th>\n",
       "      <th>x0_Chinstrap</th>\n",
       "      <th>x0_Gentoo</th>\n",
       "      <th>x1_Dream</th>\n",
       "      <th>x1_Torgersen</th>\n",
       "      <th>x2_MALE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>321</th>\n",
       "      <td>55.9</td>\n",
       "      <td>17.0</td>\n",
       "      <td>228.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>265</th>\n",
       "      <td>43.6</td>\n",
       "      <td>13.9</td>\n",
       "      <td>217.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>38.8</td>\n",
       "      <td>20.0</td>\n",
       "      <td>190.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>308</th>\n",
       "      <td>47.5</td>\n",
       "      <td>14.0</td>\n",
       "      <td>212.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>53.5</td>\n",
       "      <td>19.9</td>\n",
       "      <td>205.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     culmen_length_mm  culmen_depth_mm  flipper_length_mm  x0_Chinstrap  \\\n",
       "321              55.9             17.0              228.0           0.0   \n",
       "265              43.6             13.9              217.0           0.0   \n",
       "36               38.8             20.0              190.0           0.0   \n",
       "308              47.5             14.0              212.0           0.0   \n",
       "191              53.5             19.9              205.0           1.0   \n",
       "\n",
       "     x0_Gentoo  x1_Dream  x1_Torgersen  x2_MALE  \n",
       "321        1.0       0.0           0.0      1.0  \n",
       "265        1.0       0.0           0.0      0.0  \n",
       "36         0.0       1.0           0.0      1.0  \n",
       "308        1.0       0.0           0.0      0.0  \n",
       "191        0.0       1.0           0.0      1.0  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "birds = sns.load_dataset('penguins')\n",
    "# For simplicity's sake we'll limit our analysis to the numeric columns.\n",
    "numeric = birds[['culmen_length_mm', 'culmen_depth_mm',\n",
    "                 'flipper_length_mm', 'body_mass_g']]\n",
    "# We'll drop the rows with null values\n",
    "cleaned = birds.dropna()\n",
    "X_train, X_test, y_train, y_test = train_test_split(cleaned.drop('body_mass_g',\n",
    "                                                              axis=1),\n",
    "                                                   cleaned['body_mass_g'],\n",
    "                                                   random_state=42)\n",
    "ohe = OneHotEncoder(drop='first')\n",
    "dummies = ohe.fit_transform(X_train[['species', 'island', 'sex']])\n",
    "dummies_df = pd.DataFrame(dummies.todense(), columns=ohe.get_feature_names(),\n",
    "                         index=X_train.index)\n",
    "X_train_df = pd.concat([X_train[['culmen_length_mm', 'culmen_depth_mm',\n",
    "                                'flipper_length_mm']], dummies_df], axis=1)\n",
    "X_train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=False)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lasso = Lasso(alpha=0.5)\n",
    "lasso.fit(X_train_df, y_train)\n",
    "\n",
    "lin = LinearRegression()\n",
    "lin.fit(X_train_df, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lasso Regression Coefficients are:[  15.10768488   68.49779406   17.13019293 -228.05639523 1026.73620242\n",
      "    8.66504461  -44.14246672  386.14456129]\n",
      "Lasso Linear Regression Intercept:-1594.5702008510716\n"
     ]
    }
   ],
   "source": [
    "print(\"Lasso Regression Coefficients are:{}\".format(lasso.coef_))\n",
    "print(\"Lasso Linear Regression Intercept:{}\".format(lasso.intercept_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Try at least 3 different model specifications, using polynomials, interaction terms, etc\n",
    "- Group 1: Use AIC and BIC to pick your \"best\" model specification using Linear Regression\n",
    "- Group 2: Use Ridge AND experiement with different values of alpha to find the \"best\" model. Compare MSE in train and test for each model specification.\n",
    "- Group 3: Use Lasso AND experiment with different values of alpha to find the \"best\" model. Compare MSE in train and test for each model specification.\n",
    "- Report your observations.\n",
    "- A graph comparing your findings and suggesting a model specification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: Summary\n",
    "\n",
    "#### Effect of $\\alpha$ in Lasso and Ridge\n",
    "\n",
    "<img src=\"lasso_effect_of_lambda.png\" alt=\"Lasso-Lambda\" style=\"width: 500px;\"/>\n",
    "\n",
    "<img src=\"ridge_effect_of_lambda.png\" alt=\"Lasso-Lambda\" style=\"width: 500px;\"/>\n",
    "\n",
    "<a name='questions'></a>\n",
    "### Questions\n",
    "\n",
    "\n",
    "\n",
    "Q. Should I do normalization for Lasso or Ridge?\n",
    "\n",
    "A. Yes? Why?\n",
    "\n",
    "Q. When we know that Ridge and Lasso is better than vanilla linear regression?\n",
    "\n",
    "A. High variation in your model --> Colinearity and too many variables.\n",
    "\n",
    "Q. How do we know whether we should choose Lasso or Ridge?\n",
    "\n",
    "A. Most of the time they perform very similar but Lasso has the feature selection property, ridge doesn't have this.\n",
    "\n",
    "Q: How do we choose $\\lambda$?\n",
    "\n",
    "A. [sklearn gridsearch](https://scikit-learn.org/stable/modules/grid_search.html#grid-search) for small models or random grid search for bigger models.\n",
    "\n",
    "#### Appendix\n",
    "<a name='appendix'></a>\n",
    "\n",
    "Here I would like to add some reading material that I found useful while working with the code.\n",
    "\n",
    "\n",
    "-  [On ridge and lasso](https://bradleyboehmke.github.io/HOML/regularized-regression.html)\n",
    "\n",
    "- [pd.get_dummies or OneHotEncoder? - Read second answer](https://stackoverflow.com/questions/36631163/pandas-get-dummies-vs-sklearns-onehotencoder-what-are-the-pros-and-cons)\n",
    "\n",
    "- [On dummy variable trap](https://www.algosome.com/articles/dummy-variable-trap-regression.html)\n",
    "\n",
    "- [sklearn.preprocessing.PolynomialFeatures documentation](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.PolynomialFeatures.html)\n",
    "\n",
    "- [A great notebook on Lasso and Ridge](https://github.com/gokererdogan/JaverianaMLCourse/blob/master/Lectures/05.pdf)\n",
    "\n",
    "- [Another good blog post on Lasso and Ridge](https://www.analyticsvidhya.com/blog/2016/01/complete-tutorial-ridge-lasso-regression-python/)\n",
    "\n",
    "- Learn.co -- Section-28 Lasso-Ridge\n",
    "\n",
    "- [Toward Datascience Article](https://towardsdatascience.com/understanding-the-bias-variance-tradeoff-165e6942b229)\n",
    "\n",
    "- [ISLR](http://faculty.marshall.usc.edu/gareth-james/ISL/) 2.2.2 The Bias-Variance Trade-off and 6.2 Shrinkage Methods\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Image Sources in order of appearance: \n",
    "- https://docs.aws.amazon.com/machine-learning/latest/dg/model-fit-underfitting-vs-overfitting.html\n",
    "\n",
    "- https://towardsdatascience.com/ensemble-methods-bagging-boosting-and-stacking-c9214a10a205\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
